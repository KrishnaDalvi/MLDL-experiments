# ======================= SINGLE CELL CODE =======================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error

# -------------------- Load Dataset --------------------
movies = pd.read_csv("movies.csv")

# -------------------- Feature Engineering --------------------

# Extract year from title
movies['year'] = movies['title'].str.extract(r'\((\d{4})\)')
movies['year'] = pd.to_numeric(movies['year'], errors='coerce')

# Create numeric features
movies['title_length'] = movies['title'].apply(len)
movies['genre_count'] = movies['genres'].apply(lambda x: len(str(x).split('|')))

# Drop missing values
movies = movies.dropna()

# Define Features (X) and Target (y)
X = movies[['movieId', 'title_length', 'genre_count']]
y = movies['year']

# -------------------- Train-Test Split --------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# -------------------- Scaling --------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# -------------------- Models --------------------
linear = LinearRegression()
ridge = Ridge(alpha=10)
lasso = Lasso(alpha=0.1)

linear.fit(X_train_scaled, y_train)
ridge.fit(X_train_scaled, y_train)
lasso.fit(X_train_scaled, y_train)

# -------------------- Predictions --------------------
y_pred_linear = linear.predict(X_test_scaled)
y_pred_ridge = ridge.predict(X_test_scaled)
y_pred_lasso = lasso.predict(X_test_scaled)

# ================== PLOT 1: Actual vs Predicted ==================
plt.figure(figsize=(8,6))

plt.scatter(y_test, y_pred_linear, alpha=0.4, label="Linear Regression")
plt.scatter(y_test, y_pred_ridge, alpha=0.4, label="Ridge Regression")
plt.scatter(y_test, y_pred_lasso, alpha=0.4, label="Lasso Regression")

# Perfect line
plt.plot([y_test.min(), y_test.max()],
         [y_test.min(), y_test.max()],
         'b--')

plt.xlabel("Actual Year")
plt.ylabel("Predicted Year")
plt.title("Actual vs Predicted Values")
plt.legend()
plt.show()

# ================== PLOT 2: Coefficient Comparison ==================
features = X.columns

plt.figure(figsize=(10,6))

plt.plot(features, linear.coef_, marker='o', label="Linear Regression")
plt.plot(features, ridge.coef_, marker='o', label="Ridge Regression")
plt.plot(features, lasso.coef_, marker='o', label="Lasso Regression")

plt.axhline(0, linestyle='--')
plt.title("Feature Coefficients Comparison")
plt.ylabel("Coefficient Value")
plt.xticks(rotation=45)
plt.legend()
plt.show()

# -------------------- Metrics --------------------
print("Linear RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_linear)))
print("Ridge RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))
print("Lasso RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))

# ======================= END =======================
